{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Quiteria89/Deploy-Web/blob/master/notebook_desafio2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITgjsnUK1WnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "pzVTw_441WnW",
        "colab_type": "text"
      },
      "source": [
        "# MARATONA BEHIND THE CODE 2020\n",
        "\n",
        "## DESAFIO 2: UNINASSAU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y8a0WJel1WnX",
        "colab_type": "text"
      },
      "source": [
        "### Instalando bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUEizdo3RaY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Y5iDtQq1WnX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install scikit-learn --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BlSN3Nu1Wnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install xgboost --upgrade"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n16RNrn0BkmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install -U imbalanced-learn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVsHokJBcsOW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install imblearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CbCGXu6C1Wne",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Em seguida iremos importar diversas bibliotecas que serão utilizadas:\n",
        "\n",
        "# Pacote para trabalhar com JSON\n",
        "import json\n",
        "\n",
        "# Pacote para realizar requisições HTTP\n",
        "import requests\n",
        "\n",
        "# Pacote para exploração e análise de dados\n",
        "import pandas as pd\n",
        "\n",
        "# Pacote com métodos numéricos e representações matriciais\n",
        "import numpy as np\n",
        "\n",
        "# Pacote para construção de modelo baseado na técnica Gradient Boosting\n",
        "from xgboost import XGBClassifier\n",
        "from xgboost import plot_tree\n",
        "\n",
        "# Pacotes do scikit-learn para pré-processamento de dados\n",
        "# \"SimpleImputer\" é uma transformação para preencher valores faltantes em conjuntos de dados\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Pacotes do scikit-learn para treinamento de modelos e construção de pipelines\n",
        "# Método para separação de conjunto de dados em amostras de treino e teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "# Método para criação de modelos baseados em árvores de decisão\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "# Classe para a criação de uma pipeline de machine-learning\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Pacotes do scikit-learn para avaliação de modelos\n",
        "# Métodos para validação cruzada do modelo criado\n",
        "from sklearn.model_selection import KFold, cross_validate\n",
        "#\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import seaborn as sns\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZGbDjgc1Wnh",
        "colab_type": "text"
      },
      "source": [
        "## Download dos conjuntos de dados em formato .csv"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-k-mnhdX1Wni",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/maratonadev-br/desafio-2-2020/master/Assets/Data/dataset_desafio_2.csv\n",
        "df_training_dataset = pd.read_csv(r'dataset_desafio_2.csv')\n",
        "df_training_dataset.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRMTFUK71Wnl",
        "colab_type": "text"
      },
      "source": [
        "Temos 15 colunas presentes no dataset fornecido, sendo dezessete delas variáveis características (dados de entrada) e um delas uma variável-alvo (que queremos que o nosso modelo seja capaz de prever). \n",
        "\n",
        "As variáveis características são:\n",
        "\n",
        "    MATRICULA       - número de matrícula do estudante\n",
        "    NOME            - nome completo do estudante\n",
        "    REPROVACOES_DE  - número de reprovações na disciplina de ``Direito Empresarial``\n",
        "    REPROVACOES_EM  - número de reprovações na disciplina de ``Empreendedorismo``\n",
        "    REPROVACOES_MF  - número de reprovações na disciplina de ``Matemática Financeira``\n",
        "    REPROVACOES_GO  - número de reprovações na disciplina de ``Gestão Operacional``\n",
        "    NOTA_DE         - média simples das notas do aluno na disciplina de ``Direito Empresarial`` (0-10)\n",
        "    NOTA_EM         - média simples das notas do aluno na disciplina de ``Empreendedorismo`` (0-10)\n",
        "    NOTA_MF         - média simples das notas do aluno na disciplina de ``Matemática Financeira`` (0-10)\n",
        "    NOTA_GO         - média simples das notas do aluno na disciplina de ``Gestão Operacional`` (0-10)\n",
        "    INGLES          - variável binária que indica se o estudante tem conhecimento em língua inglesa (0 -> sim ou 1 -> não).\n",
        "    H_AULA_PRES     - horas de estudo presencial realizadas pelo estudante\n",
        "    TAREFAS_ONLINE  - número de tarefas online entregues pelo estudante\n",
        "    FALTAS          - número de faltas acumuladas do estudante (todas disciplinas)\n",
        "    \n",
        "A variável-alvo é:\n",
        "\n",
        "    PERFIL               - uma *string* que indica uma de cinco possibilidades: \n",
        "        \"EXCELENTE\"      - Estudante não necessita de mentoria\n",
        "        \"MUITO BOM\"      - Estudante não necessita de mentoria\n",
        "        \"HUMANAS\"        - Estudante necessita de mentoria exclusivamente em matérias com conteúdo de ciências humanas\n",
        "        \"EXATAS\"         - Estudante necessita de mentoria apenas em disciplinas com conteúdo de ciências exatas\n",
        "        \"DIFICULDADE\"    - Estudante necessita de mentoria em duas ou mais disciplinas\n",
        "        \n",
        "Com um modelo capaz de classificar um estudante em uma dessas categorias, podemos automatizar parte da mentoria estudantil através de assistentes virtuais, que serão capazes de recomendar práticas de estudo e conteúdo personalizado com base nas necessidades de cada aluno."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZX_DLkR51Wnl",
        "colab_type": "text"
      },
      "source": [
        "### Explorando os dados fornecidos\n",
        "\n",
        "Podemos continuar a exploração dos dados fornecidos com a função ``info()``:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuhGP-oh1Wnm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_training_dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WOA0Eiq1Wnp",
        "colab_type": "text"
      },
      "source": [
        "É notado que existem variáveis do tipo ``float64`` (números \"decimais\"), variáveis do tipo ``int64`` (números inteiros) e do tipo ``object`` (nesse caso são *strings*, ou texto). \n",
        "\n",
        "Como a maioria dos algoritmos de aprendizado estatístico supervisionado só aceita valores numéricos como entrada, é necessário então o pré-processamento das variáveis do tipo \"object\" antes de usar esse dataset como entrada para o treinamento de um modelo. Também é notado que existem valores faltantes em várias colunas. Esses valores faltantes também devem ser tratados antes de serem construídos modelos com esse conjunto de dados base."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XdC1Y_Mu1Wnq",
        "colab_type": "text"
      },
      "source": [
        "A função ``describe()`` gera várias informações sobre as variáveis numéricas que também podem ser úteis:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hujjW2WE1Wnr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_training_dataset.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZCKpr1s1Wnt",
        "colab_type": "text"
      },
      "source": [
        "### Visualizações\n",
        "\n",
        "Para visualizar o dataset fornecido, podemos utilizar as bibliotecas ``matplotlib`` e ``seaborn``:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-8rVc3G1Wnu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wA7pqEYi1Wnw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(28, 4))\n",
        "\n",
        "sns.countplot(ax=axes[0], x='REPROVACOES_DE', data=df_training_dataset)\n",
        "sns.countplot(ax=axes[1], x='REPROVACOES_EM', data=df_training_dataset)\n",
        "sns.countplot(ax=axes[2], x='REPROVACOES_MF', data=df_training_dataset)\n",
        "sns.countplot(ax=axes[3], x='REPROVACOES_GO', data=df_training_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kged3Gzy1Wnz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(28, 4))\n",
        "\n",
        "sns.distplot(df_training_dataset['NOTA_DE'], ax=axes[0])\n",
        "sns.distplot(df_training_dataset['NOTA_EM'], ax=axes[1])\n",
        "sns.distplot(df_training_dataset['NOTA_MF'], ax=axes[2])\n",
        "sns.distplot(df_training_dataset['NOTA_GO'].dropna(), ax=axes[3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "Dz7FJSOz1Wn3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(28, 4))\n",
        "\n",
        "sns.countplot(ax=axes[0], x='INGLES', data=df_training_dataset)\n",
        "sns.countplot(ax=axes[1], x='FALTAS', data=df_training_dataset)\n",
        "sns.countplot(ax=axes[2], x='H_AULA_PRES', data=df_training_dataset)\n",
        "sns.countplot(ax=axes[3], x='TAREFAS_ONLINE', data=df_training_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDZK7_R91Wn7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.plot()\n",
        "sns.countplot(x='PERFIL', data=df_training_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XxoY9uo1Wn_",
        "colab_type": "text"
      },
      "source": [
        "## ** ATENÇÃO **\n",
        "\n",
        "Você pode notar pela figura acima que este dataset é desbalanceado, isto é, a quantidade de amostras para cada classe que desejamos classificar é bem discrepante. O participante é livre para adicionar ou remover **LINHAS** no dataset fornecido, inclusive utilizar bibliotecas para balanceamento com ``imblearn``.\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHiNoDZ-1Wn_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cVnbOkw1WoC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-8gccBf1WoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9doeUZQz1WoH",
        "colab_type": "text"
      },
      "source": [
        "### Realizando o pré-processamento dos dados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgRCl0ua1WoH",
        "colab_type": "text"
      },
      "source": [
        "#### Transformação 1: excluindo colunas do dataset\n",
        "\n",
        "Para a criação de uma transformação de dados personalizada no scikit-learn, é necessária basicamente a criação de uma classe com os métodos ``transform`` e ``fit``. No método transform será executada a lógica da nossa transformação.\n",
        "\n",
        "Na próxima célula é apresentado o código completo de uma transformação ``DropColumns`` para a remoção de colunas de um DataFrame pandas."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCZOr_ak1WoH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "\n",
        "\n",
        "# All sklearn Transforms must have the `transform` and `fit` methods\n",
        "class DropColumns(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, columns):\n",
        "        self.columns = columns\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "    \n",
        "    def transform(self, X):\n",
        "        # Primeiro realizamos a cópia do dataframe 'X' de entrada\n",
        "        data = X.copy()\n",
        "        # Retornamos um novo dataframe sem as colunas indesejadas\n",
        "        return data.drop(labels=self.columns, axis='columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wLtcfiv1WoM",
        "colab_type": "text"
      },
      "source": [
        "Para aplicar essa transformação em um DataFrame pandas, basta instanciar um objeto *DropColumns* e chamar o método transform()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qL8dbVmF1WoM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instanciando uma transformação DropColumns\n",
        "rm_columns = DropColumns(\n",
        "    columns=[\"NOME\"]  # Essa transformação recebe como parâmetro uma lista com os nomes das colunas indesejadas\n",
        ")\n",
        "\n",
        "print(rm_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEA9zMlh1WoO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizando as colunas do dataset original\n",
        "print(\"Colunas do dataset original: \\n\")\n",
        "print(df_training_dataset.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpsuiFID1WoR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Aplicando a transformação ``DropColumns`` ao conjunto de dados base\n",
        "rm_columns.fit(X=df_training_dataset)\n",
        "\n",
        "# Reconstruindo um DataFrame Pandas com o resultado da transformação\n",
        "df_training_dataset_2 = pd.DataFrame.from_records(\n",
        "    data=rm_columns.transform(\n",
        "        X=df_training_dataset\n",
        "    ),\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKfa9MI31WoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizando as colunas do dataset transformado\n",
        "print(\"Colunas do dataset após a transformação ``DropColumns``: \\n\")\n",
        "print(df_training_dataset_2.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4fcJ80h1WoW",
        "colab_type": "text"
      },
      "source": [
        "Nota-se que a coluna \"NOME\" foi removida e nosso dataset agora poossui apenas 17 colunas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oh8Tzkj41WoW",
        "colab_type": "text"
      },
      "source": [
        "#### Transformação 2: tratando dados faltantes\n",
        "\n",
        "Para tratar os dados faltantes em nosso conjunto de dados, iremos agora utilizar uma transformação pronta da biblioteca scikit-learn, chamada **SimpleImputer**.\n",
        "\n",
        "Essa transformação permite diversas estratégias para o tratamento de dados faltantes. A documentação oficial pode ser encontrada em: https://scikit-learn.org/stable/modules/generated/sklearn.impute.SimpleImputer.html\n",
        "\n",
        "Neste exemplo iremos simplesmente transformar todos os valores faltantes em zero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HmhvjQhy1WoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criação de um objeto ``SimpleImputer``\n",
        "si = SimpleImputer(\n",
        "    missing_values=np.nan,  # os valores faltantes são do tipo ``np.nan`` (padrão Pandas)\n",
        "    strategy='constant',  # a estratégia escolhida é a alteração do valor faltante por uma constante\n",
        "    fill_value=0,  # a constante que será usada para preenchimento dos valores faltantes é um int64=0.\n",
        "    verbose=0,\n",
        "    copy=True\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w72NLDx21WoZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizando os dados faltantes do dataset após a primeira transformação (df_data_2)\n",
        "print(\"Valores nulos antes da transformação SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset_2.isnull().sum(axis = 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMy500ZC1Woc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Aplicamos o SimpleImputer ``si`` ao conjunto de dados df_data_2 (resultado da primeira transformação)\n",
        "si.fit(X=df_training_dataset_2)\n",
        "\n",
        "# Reconstrução de um novo DataFrame Pandas com o conjunto imputado (df_data_3)\n",
        "df_training_dataset_3 = pd.DataFrame.from_records(\n",
        "    data=si.transform(\n",
        "        X=df_training_dataset_2\n",
        "    ),  # o resultado SimpleImputer.transform(<<pandas dataframe>>) é lista de listas\n",
        "    columns=df_training_dataset_2.columns  # as colunas originais devem ser conservadas nessa transformação\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4yoZchmM1Wog",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Visualizando os dados faltantes do dataset após a segunda transformação (SimpleImputer) (df_data_3)\n",
        "print(\"Valores nulos no dataset após a transformação SimpleImputer: \\n\\n{}\\n\".format(df_training_dataset_3.isnull().sum(axis = 0)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqEPag171Wok",
        "colab_type": "text"
      },
      "source": [
        "Nota-se que não temos mais nenhum valor faltante no nosso conjunto de dados :)\n",
        "\n",
        "Vale salientar que nem sempre a alteração dos valores faltantes por 0 é a melhor estratégia. O participante é incentivado a estudar e implementar estratégias diferentes de tratamento dos valores faltantes para aprimorar seu modelo e melhorar sua pontuação final."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x94k71KM1Wok",
        "colab_type": "text"
      },
      "source": [
        "### Treinando um modelo de classificação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1zJdqox1Wol",
        "colab_type": "text"
      },
      "source": [
        "Finalizado o pré-processamento, já temos o conjunto de dados no formato necessário para o treinamento do nosso modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHJ0bhEy1Wol",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_training_dataset_3.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8UWlAeYSY2hd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_training_dataset_3.PERFIL.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdJHA7Gx1Woo",
        "colab_type": "text"
      },
      "source": [
        "No exemplo fornecido, iremos utilizar todas as colunas, exceto a coluna **LABELS** como *features* (variáveis de entrada).\n",
        "\n",
        "A variável **LABELS** será a variável-alvo do modelo, conforme descrito no enunciado do desafio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bSTT88Tl1Wop",
        "colab_type": "text"
      },
      "source": [
        "#### Definindo as features do modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wrQNvJD1Wop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Definição das colunas que serão features (nota-se que a coluna NOME não está presente)\n",
        "features = [\n",
        "    \"MATRICULA\", 'REPROVACOES_DE', 'REPROVACOES_EM', \"REPROVACOES_MF\", \"REPROVACOES_GO\",\n",
        "    \"NOTA_DE\", \"NOTA_EM\", \"NOTA_MF\", \"NOTA_GO\",\n",
        "    \"INGLES\", \"H_AULA_PRES\", \"TAREFAS_ONLINE\", \"FALTAS\", \n",
        "]\n",
        "\n",
        "# Definição da variável-alvo\n",
        "target = [\"PERFIL\"]\n",
        "\n",
        "# Preparação dos argumentos para os métodos da biblioteca ``scikit-learn``\n",
        "X = df_training_dataset_3[features]\n",
        "y = df_training_dataset_3[target]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO9yH7Xu1Wos",
        "colab_type": "text"
      },
      "source": [
        "O conjunto de entrada (X):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsbkVJIj1Wos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyuNGuik1Wow",
        "colab_type": "text"
      },
      "source": [
        "As variáveis-alvo correspondentes (y):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8PaOCxC1Wox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xjsWSYw5vFi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Count\n",
        "df_training_dataset_3.groupby(by=['PERFIL'])['MATRICULA'].agg(['count'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xLywz1Ad1Woz",
        "colab_type": "text"
      },
      "source": [
        "#### Separando o dataset em um conjunto de treino e um conjunto de teste"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsqXo9841Wo0",
        "colab_type": "text"
      },
      "source": [
        "Iremos separar o dataset fornecido em dois grupos: um para treinar nosso modelo, e outro para testarmos o resultado através de um teste cego. A separação do dataset pode ser feita facilmente com o método *train_test_split()* do scikit-learn:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYs5xipe1Wo0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separação dos dados em um conjunto de treino e um conjunto de teste\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=133)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-SMDuRS-1Wo3",
        "colab_type": "text"
      },
      "source": [
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KY1fJzCI1Wo3",
        "colab_type": "text"
      },
      "source": [
        "#### Criando um modelo baseado em árvores de decisão"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBbZlDYB1Wo4",
        "colab_type": "text"
      },
      "source": [
        "No exemplo fornecido iremos criar um classificador baseado em **árvores de decisão**.\n",
        "\n",
        "Material teórico sobre árvores de decisão na documentação oficial do scikit-learn: https://scikit-learn.org/stable/modules/tree.html\n",
        "\n",
        "O primeiro passo é basicamente instanciar um objeto *DecisionTreeClassifier()* da biblioteca scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRHHtkbe1Wo4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Criação de uma árvore de decisão com a biblioteca ``scikit-learn``:\n",
        "#decision_tree = XGBClassifier()\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "decision_tree = DecisionTreeClassifier(max_depth=15).fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_gcXG2d1Wo8",
        "colab_type": "text"
      },
      "source": [
        "#### Testando o classificador baseado em árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-hbp0MZP1Wo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Treino do modelo (é chamado o método *fit()* com os conjuntos de treino)\n",
        "#decision_tree.fit(X_train,y_train)\n",
        "decision_tree.fit(X_train, y_train)\n",
        "decision_tree.score(X_test,y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3kKEaQy8okG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Target - Dataset\n",
        "predict_train =decision_tree.predict(X_train)\n",
        "print('\\nTarget alcançada ',predict_train) \n",
        " \n",
        "# Acurácia alcançada pela árvore de decisão\n",
        "accuracy_train = accuracy_score(y_train,predict_train)\n",
        "print('\\nAcurácia alcançada : {}%'.format(100*round(accuracy_train), 2))\n",
        " \n",
        "# prever o alvo no conjunto de dados de teste\n",
        "predict_test = decision_tree.predict(X_test)\n",
        "print('\\nTarget alcançada nos dados:',predict_test)\n",
        " \n",
        "# Acurácia alcançada pela árvore de decisão - Teste\n",
        "accuracy_test = accuracy_score(y_test,predict_test)\n",
        "print('\\nAcurácia alcançada no teste:{}%'.format(100*round(accuracy_test), 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iraJf651Wo-",
        "colab_type": "text"
      },
      "source": [
        "#### Execução de predições e avaliação da árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kNfAT4e1Wo_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Realização de teste cego no modelo criado\n",
        "y_pred = decision_tree.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCbu4gKj1WpB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFlG9LvA1WpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YSZki0p1WpH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Acurácia alcançada pela árvore de decisão\n",
        "print(\"Acurácia: {}%\".format(100*round(accuracy_score(y_test, y_pred), 2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nCUjFPiJ85o9",
        "colab_type": "text"
      },
      "source": [
        "# **Importancia de cada feature**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ceiEhInf2jSH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rfc_fi = pd.DataFrame({'feature':X.columns,'importance':decision_tree.feature_importances_}).sort_values(by='importance',ascending=False)\n",
        "sns.catplot(x='feature',y='importance',data=rfc_fi,kind='bar',aspect=1.5).set_xticklabels(rotation=90);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCTSXROh_KhG",
        "colab_type": "text"
      },
      "source": [
        "# Analisando a qualidade do modelo através da matriz de **confusão**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N4aQ_2_u-jnR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, target_names, title='Confusion matrix', cmap=None, normalize=True):\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=45)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uimtZah4_XoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "plot_confusion_matrix(confusion_matrix(y_test, y_pred), ['EXCELENTE', 'MUITO BOM', 'HUMANAS', 'EXATAS', 'DIFICULDADE'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi-d2eZ62kkM",
        "colab_type": "text"
      },
      "source": [
        "# Gera dados sintéticos da classe **minoritária**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgTuqurXAfX9",
        "colab_type": "text"
      },
      "source": [
        "# Instância o **SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ao11JgLBAXV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "from imblearn.over_sampling import SMOTE, ADASYN\n",
        "X_resampled, y_resampled = SMOTE().fit_sample(X_train, y_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niJ3heGoAr9F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prever o alvo no conjunto de dados de teste\n",
        "preds = decision_tree.predict(X_test)\n",
        "print('\\nTarget alcançada nos dados:',preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4JC19i0QF8T8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "beb8a4dc-30c1-4da7-fd4a-b2503872ab72"
      },
      "source": [
        "#Checa a acurácia do modelo\n",
        "accuracy_score(y_test, preds)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7513333333333333"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2k0GlLnC1WpL",
        "colab_type": "text"
      },
      "source": [
        "<hr>\n",
        "\n",
        "## Scoring dos dados necessários para entregar a solução"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1VZjrhN1WpM",
        "colab_type": "text"
      },
      "source": [
        "Como entrega da sua solução, esperamos os resultados classificados no seguinte dataset chamado \"to_be_scored.csv\":"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oe6xI9DN1WpN",
        "colab_type": "text"
      },
      "source": [
        "### Download da \"folha de respostas\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xXoWzGk1WpO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget --no-check-certificate --content-disposition https://raw.githubusercontent.com/vanderlei-test/dataset-uninassau/master/to_be_scored_uninassau.csv\n",
        "df_to_be_scored = pd.read_csv(r'to_be_scored_uninassau.csv')\n",
        "df_to_be_scored.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2jTV6q9M1WpS",
        "colab_type": "text"
      },
      "source": [
        "# Atenção!\n",
        "\n",
        "O dataframe ``to_be_scored`` é a sua \"folha de respostas\". Note que a coluna \"PERFIL\" não existe nessa amostra, que não pode ser então utilizada para treino de modelos de aprendizado supervisionado."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBcSfjDh1WpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_to_be_scored.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPMjgUJr1WpZ",
        "colab_type": "text"
      },
      "source": [
        "<hr>\n",
        "\n",
        "# Atenção!\n",
        "\n",
        "# Para poder aplicar seu modelo e classificar a folha de respostas, você precisa primeiro aplicar as mesmas transformações com colunas que você aplicou no dataset de treino.\n",
        "\n",
        "# Não remova ou adicione linhas na folha de respostas. \n",
        "\n",
        "# Não altere a ordem das linhas na folha de respostas.\n",
        "\n",
        "# Ao final, as 500 entradas devem estar classificadas, com os valores previstos em uma coluna chamada \"target\"\n",
        "\n",
        "<hr>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_0wFCMu1WpZ",
        "colab_type": "text"
      },
      "source": [
        "Na célula abaixo, repetimos rapidamente os mesmos passos de pré-processamento usados no exemplo dado com árvore de decisão"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7fS2C2q1Wpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Aplicando a transformação ``DropColumns`` ao conjunto de dados base\n",
        "rm_columns.fit(X=df_to_be_scored)\n",
        "\n",
        "# Reconstruindo um DataFrame Pandas com o resultado da transformação\n",
        "df_to_be_scored_2 = pd.DataFrame.from_records(\n",
        "    data=rm_columns.transform(\n",
        "        X=df_to_be_scored\n",
        "    ),\n",
        ")\n",
        "\n",
        "# Aplicamos o SimpleImputer ``si`` ao conjunto de dados df_data_2 (resultado da primeira transformação)\n",
        "si.fit(X=df_to_be_scored_2)\n",
        "\n",
        "# Reconstrução de um novo DataFrame Pandas com o conjunto imputado (df_data_3)\n",
        "df_to_be_scored_3 = pd.DataFrame.from_records(\n",
        "    data=si.transform(\n",
        "        X=df_to_be_scored_2\n",
        "    ),  # o resultado SimpleImputer.transform(<<pandas dataframe>>) é lista de listas\n",
        "    columns=df_to_be_scored_2.columns  # as colunas originais devem ser conservadas nessa transformação\n",
        ")\n",
        "\n",
        "df_to_be_scored_3.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XX8zaD4W1Wpd",
        "colab_type": "text"
      },
      "source": [
        "<hr>\n",
        "\n",
        "Pode ser verificado abaixo que as colunas da folha de resposta agora são idênticas às que foram usadas para treinar o modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0kg43l151Wpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_to_be_scored_3.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWBSywKN1Wpi",
        "colab_type": "text"
      },
      "source": [
        "### Executando as predições na \"folha de respostas\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WY05FQIP1Wpj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = decision_tree.predict(df_to_be_scored_3)\n",
        "df_to_be_scored_3['target'] = y_pred\n",
        "df_to_be_scored_3.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VHlA2tZ1Wpl",
        "colab_type": "text"
      },
      "source": [
        "### Salvando a folha de respostas como um arquivo .csv para ser submetido"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM6nH2yJ1Wpm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#project.save_data(file_name=\"results.csv\", data=df_to_be_scored_3.to_csv(index=False))\n",
        "\n",
        "df = pd.DataFrame(df_to_be_scored_3)\n",
        "  \n",
        "# saving the dataframe \n",
        "df.to_csv('results.csv',index=False) \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5Xe-n5I1Wpo",
        "colab_type": "text"
      },
      "source": [
        "# Atenção\n",
        "\n",
        "# A execução da célula acima irá criar um novo \"data asset\" no seu projeto no Watson Studio. Você precisará realizar o download deste arquivo juntamente com este notebook e criar um arquivo zip com os arquivos **results.csv** e **notebook.ipynb** para submissão. (os arquivos devem estar nomeados desta forma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9c5e2Ih1Wpo",
        "colab_type": "text"
      },
      "source": [
        "<hr>\n",
        "\n",
        "## Parabéns!\n",
        "\n",
        "Se você já está satisfeito com a sua solução, vá até a página abaixo e envie os arquivos necessários para submissão.\n",
        "\n",
        "# https://uninassau.maratona.dev\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XIMTi5W-1Wpo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFUqbe0_1Wps",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}